require('dotenv').config(); // Load environment variables from a .env file
const { Buffer } = require('node:buffer'); // Import Buffer for handling binary data
const EventEmitter = require('events'); // Import EventEmitter for handling events
const fetch = require('node-fetch'); // Import fetch for making HTTP requests

/**
 * TextToSpeechService Class
 *
 * This class extends EventEmitter to provide text-to-speech (TTS) capabilities using the Deepgram API. 
 * It listens for GPT-generated text responses, converts them to speech, and emits the resulting audio 
 * in base64 format. This is particularly useful for real-time voice interactions where text responses 
 * need to be spoken aloud.
 *
 * Key Features:
 * - Listens for partial responses generated by GPT-4 and converts them into speech.
 * - Utilizes the Deepgram API for generating speech, configured with specific parameters like model, 
 *   encoding, and sample rate.
 * - Manages the order of responses to ensure the correct sequence in the speech output.
 * - Emits the generated speech in base64 format along with metadata, which can be used by other parts 
 *   of the system.
 */

class TextToSpeechService extends EventEmitter {
  constructor() {
    super();
    this.nextExpectedIndex = 0; // Initialize the expected index for the next response
    this.speechBuffer = {}; // Buffer to store speech data for out-of-order responses
  }

  /**
   * Generates speech from a given GPT reply and emits the result.
   *
   * @param {Object} gptReply - The GPT reply containing the partial response and its index.
   * @param {number} interactionCount - The current interaction count to track the sequence of interactions.
   */
  async generate(gptReply, interactionCount) {
    const { partialResponseIndex, partialResponse } = gptReply;

    // If there's no partial response, exit the function
    if (!partialResponse) { return; }

    try {
      // Send a POST request to Deepgram API to convert text to speech
      const response = await fetch(
        `https://api.deepgram.com/v1/speak?model=${process.env.VOICE_MODEL}&encoding=mulaw&sample_rate=8000&container=none`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Token ${process.env.DEEPGRAM_API_KEY}`, // Authorization header with API key
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            text: partialResponse, // The text to be converted to speech
          }),
        }
      );

      // If the request is successful, process the response
      if (response.status === 200) {
        try {
          const blob = await response.blob(); // Convert the response to a blob
          const audioArrayBuffer = await blob.arrayBuffer(); // Convert the blob to an ArrayBuffer
          const base64String = Buffer.from(audioArrayBuffer).toString('base64'); // Convert the ArrayBuffer to a base64 string
          
          // Emit the generated speech along with its index and other metadata
          this.emit('speech', partialResponseIndex, base64String, partialResponse, interactionCount);
        } catch (err) {
          console.log(err); // Log any errors that occur during processing
        }
      } else {
        console.log('Deepgram TTS error:'); // Log an error if the Deepgram API request fails
        console.log(response);
      }
    } catch (err) {
      console.error('Error occurred in TextToSpeech service'); // Log any network or other errors
      console.error(err);
    }
  }
}

module.exports = { TextToSpeechService }; // Export the TextToSpeechService class
